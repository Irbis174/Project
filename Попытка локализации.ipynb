{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0831bd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, Conv2D, MaxPooling2D, BatchNormalization, Dropout\n",
    "import numpy as np\n",
    "import cv2 \n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c9f599c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (208,208)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea8b96f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _сorrecting_data():\n",
    "    x = []\n",
    "    y = []\n",
    "    boxes = []\n",
    "    df = pd.read_csv('_annotations.csv') \n",
    "    for x1,y1,x2,y2 in zip(df['xmin'].apply(lambda x: x // 2), list(df['ymin'].apply(lambda x: x // 2)), \n",
    "                       list(df['xmax'].apply(lambda x: x // 2)), list(df['ymax'].apply(lambda x: x // 2))):\n",
    "        arr = [x1, y1, x2, y2]\n",
    "        boxes.append(arr)\n",
    "    return df, boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a4eb305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_metrics(df):\n",
    "    images = []\n",
    "    \n",
    "    for index, i in df.iterrows():\n",
    "        image = cv2.imread(index)\n",
    "        images.append(image)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6357e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _data(df):\n",
    "    x = []\n",
    "    y = []\n",
    "    boxes = []\n",
    "    for index, g in df.iterrows():\n",
    "        if (df['height'][index] !=  0) and (df['width'][index] !=  0):\n",
    "            break\n",
    "        else:\n",
    "            boxes.append([None,None,None,None])\n",
    "    for x1,y1,x2,y2 in zip(df['xmin'].apply(lambda x: x // 2), list(df['ymin'].apply(lambda x: x // 2)), \n",
    "                   list(df['xmax'].apply(lambda x: x // 2)), list(df['ymax'].apply(lambda x: x // 2))):\n",
    "        arr = [x1, y1, x2, y2]\n",
    "        boxes.append(arr)\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5151edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __data(df):\n",
    "    x = []\n",
    "    y = []\n",
    "    boxes = []\n",
    "#     for index, g in df.iterrows():\n",
    "#         if (df['height'][index] !=  0) and (df['width'][index] !=  0):\n",
    "#             break\n",
    "#         else:\n",
    "#             boxes.append([0,0,0,0])\n",
    "    for height, width, x1, y1, x2, y2 in zip(df['height'], df['width'], df['xmin'].apply(lambda x: x // 2), list(df['ymin'].apply(lambda x: x // 2)), \n",
    "                   list(df['xmax'].apply(lambda x: x // 2)), list(df['ymax'].apply(lambda x: x // 2))):\n",
    "        if height == 0 and width ==0:\n",
    "            boxes.append([-1,-1,-1,-1])\n",
    "        else:\n",
    "            arr = [int(x1), int(y1), int(x2), int(y2)]\n",
    "            boxes.append(arr)\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d69ef1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_test_fun(images, coordinates, image_size):\n",
    "    scaled_regions = []\n",
    "    labels = []\n",
    "    for image, coords in zip(images, coordinates):\n",
    "        x, y, w, h = coords\n",
    "        if x + y + w + h != -4:\n",
    "        #if x is not None and y is not None and w is not None and h is not None:\n",
    "            scaled_region = cv2.resize(image, image_size)\n",
    "            scaled_regions.append(scaled_region)\n",
    "            labels.append(1)  # Предполагая, что все извлеченные области - это машины\n",
    "            # Преобразование входных данных в массивы NumPy\n",
    "        else:\n",
    "            #image = np.array(image)\n",
    "            scaled_regions.append(cv2.resize(image, image_size))\n",
    "            labels.append(0)  # Предполагая, что все извлеченные области - это не машины\n",
    "    return np.array(scaled_regions), np.array(coordinates), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0439d23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trash = pd.DataFrame({'filename': os.listdir('DataSet_cars_valid\\\\1_trash')})\n",
    "df_trash = df_trash.set_index('filename')\n",
    "df_trash = df_trash.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "168c4c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matvey\\Проект\\Project\\DataSet_cars_valid\\valid_test\n",
      "C:\\Users\\Matvey\\Проект\\Project\n"
     ]
    }
   ],
   "source": [
    "%cd DataSet_cars_valid/valid_test\n",
    "df_train, boxes_train = _сorrecting_data()\n",
    "df_train = df_train.set_index('filename')\n",
    "train = pd.concat([df_train, df_trash])\n",
    "train = train.fillna(0)\n",
    "train = train.sort_values(by = 'filename')\n",
    "boxes_train = __data(train)\n",
    "image_train = data_metrics(train)\n",
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ad9c9432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matvey\\Проект\\Project\\DataSet_cars_valid\\valid\n",
      "C:\\Users\\Matvey\\Проект\\Project\n"
     ]
    }
   ],
   "source": [
    "# %cd DataSet_cars_valid/valid\n",
    "# train, boxes_train = _сorrecting_data()\n",
    "# train = train.set_index('filename')\n",
    "# #train = pd.concat([df_train, df_trash])\n",
    "# #train = train.fillna(0)\n",
    "# #train = train.sort_values(by = 'filename')\n",
    "# boxes_train = __data(train)\n",
    "# image_train = data_metrics(train)\n",
    "# %cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67bbce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxes_train = np.array(boxes_train)\n",
    "# boxes_train = boxes_train.astype(np.int64)\n",
    "# boxes_train = boxes_train.tolist()\n",
    "\n",
    "region_train, image_coodrs,image_class  = data_test_fun(image_train, boxes_train, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a0bd76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5139"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_coodrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "795978b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m cv2\u001b[38;5;241m.\u001b[39mrectangle(image, (x, y), (x \u001b[38;5;241m+\u001b[39m width, y \u001b[38;5;241m+\u001b[39m height), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     12\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m'\u001b[39m, image)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, image in enumerate(region_train):\n",
    "    x, y, width, height = image_coodrs[i]\n",
    "    if x+y+width+height != -4:\n",
    "    #if x is not None and y is not None and width is not None and height is not None:\n",
    "#         cv2.rectangle(image, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
    "#         cv2.imshow('Image', image)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "        continue\n",
    "    else: \n",
    "        cv2.rectangle(image, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
    "        cv2.imshow('Image', image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0411a078",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, train_labels, val_labels = train_test_split(\n",
    "    region_train, image_coodrs, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "04e17509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 5, 103, 98],\n",
       "       [19, 9, 99, 52],\n",
       "       [12, 10, 96, 97],\n",
       "       ...,\n",
       "       [27, 37, 74, 72],\n",
       "       [3, 11, 100, 103],\n",
       "       [6, 22, 99, 86]], dtype=object)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a81cdc83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    " Conv2D(128, (3, 3), activation='relu', input_shape=(208, 208, 3)),  # свёрточный слой\n",
    "    #попробуй по 2-3 свёрточных слоя сделать\n",
    "    MaxPooling2D((2, 2), strides=2),  # уменьшение карт признаков\n",
    "    Dropout(0.2),  # отключение 20 процентов нейронов\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),  # свёрточный слой\n",
    "    MaxPooling2D((2, 2), strides=2),  # уменьшение карт признаков\n",
    "    Dropout(0.2),  # отключение 20 процентов нейронов\n",
    "\n",
    "    Conv2D(256, (3, 3), activation='relu'),  # свёрточный слой\n",
    "    MaxPooling2D((2, 2), strides=2),  # уменьшение карт признаков\n",
    "    Dropout(0.2),  # отключение 20 процентов нейронов\n",
    "\n",
    "    Conv2D(256, (3, 3), activation='relu'),  # свёрточный слой\n",
    "    MaxPooling2D((2, 2), strides=2),  # уменьшеи карт признаков\n",
    "    Dropout(0.2),  # отключение 20 процентов нейронов\n",
    "\n",
    "    Conv2D(512, (3, 3), activation='relu'),  # свёрточный слой\n",
    "    MaxPooling2D((2, 2), strides=2),  # уменьшение карт признаков\n",
    "    Dropout(0.2),  # отключение 20 процентов нейронов\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),  # обычные нейроны\n",
    "    Dropout(0.2),  # отключение 20 процентов нейронов\n",
    "    Dense(256, activation='relu'),  # обычные нейроны\n",
    "    Dropout(0.2),  # отключение 20 процентов нейронов\n",
    "    Dense(128, activation='relu'),  # обычные нейроны\n",
    "    Dropout(0.2),  # отключение 20 процентов нейронов\n",
    "    Dense(4, activation='linear'),  # выходной слой\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "443a166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18c97c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, train_labels, val_labels = train_test_split(\n",
    "    region_train, image_coodrs, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dac73878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "129/129 [==============================] - 23s 177ms/step - loss: 520.0608 - mse: 520.0608 - val_loss: 1800.6527 - val_mse: 1800.6527\n",
      "Epoch 2/50\n",
      "129/129 [==============================] - 19s 146ms/step - loss: 534.3242 - mse: 534.3242 - val_loss: 1594.1605 - val_mse: 1594.1605\n",
      "Epoch 3/50\n",
      "129/129 [==============================] - 18s 136ms/step - loss: 650.1933 - mse: 650.1933 - val_loss: 1773.0840 - val_mse: 1773.0840\n",
      "Epoch 4/50\n",
      "129/129 [==============================] - 27s 211ms/step - loss: 579.7346 - mse: 579.7346 - val_loss: 1746.5499 - val_mse: 1746.5499\n",
      "Epoch 5/50\n",
      "129/129 [==============================] - 19s 148ms/step - loss: 570.1947 - mse: 570.1947 - val_loss: 1403.5217 - val_mse: 1403.5217\n",
      "Epoch 6/50\n",
      "129/129 [==============================] - 20s 159ms/step - loss: 535.6735 - mse: 535.6735 - val_loss: 2186.8003 - val_mse: 2186.8003\n",
      "Epoch 7/50\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 523.1392 - mse: 523.1392 - val_loss: 1932.5085 - val_mse: 1932.5085\n",
      "Epoch 8/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 475.1948 - mse: 475.1948 - val_loss: 1643.3909 - val_mse: 1643.3909\n",
      "Epoch 9/50\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 452.6041 - mse: 452.6041 - val_loss: 1798.1101 - val_mse: 1798.1101\n",
      "Epoch 10/50\n",
      "129/129 [==============================] - 20s 152ms/step - loss: 596.5208 - mse: 596.5208 - val_loss: 2378.7556 - val_mse: 2378.7556\n",
      "Epoch 11/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 514.7999 - mse: 514.7999 - val_loss: 2244.9949 - val_mse: 2244.9949\n",
      "Epoch 12/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 508.8173 - mse: 508.8173 - val_loss: 2429.0427 - val_mse: 2429.0427\n",
      "Epoch 13/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 463.7106 - mse: 463.7106 - val_loss: 2680.9707 - val_mse: 2680.9707\n",
      "Epoch 14/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 466.1628 - mse: 466.1628 - val_loss: 2180.9717 - val_mse: 2180.9717\n",
      "Epoch 15/50\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 479.6647 - mse: 479.6647 - val_loss: 1630.0831 - val_mse: 1630.0831\n",
      "Epoch 16/50\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 608.6289 - mse: 608.6289 - val_loss: 2152.8718 - val_mse: 2152.8718\n",
      "Epoch 17/50\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 540.6958 - mse: 540.6958 - val_loss: 2161.0237 - val_mse: 2161.0237\n",
      "Epoch 18/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 516.2886 - mse: 516.2886 - val_loss: 2028.0682 - val_mse: 2028.0682\n",
      "Epoch 19/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 435.4983 - mse: 435.4983 - val_loss: 1608.7258 - val_mse: 1608.7258\n",
      "Epoch 20/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 411.5467 - mse: 411.5467 - val_loss: 2295.8284 - val_mse: 2295.8284\n",
      "Epoch 21/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 609.0597 - mse: 609.0597 - val_loss: 2504.8596 - val_mse: 2504.8596\n",
      "Epoch 22/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 588.6793 - mse: 588.6793 - val_loss: 2730.8931 - val_mse: 2730.8931\n",
      "Epoch 23/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 476.4662 - mse: 476.4662 - val_loss: 2191.4358 - val_mse: 2191.4358\n",
      "Epoch 24/50\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 485.5558 - mse: 485.5558 - val_loss: 2375.7371 - val_mse: 2375.7371\n",
      "Epoch 25/50\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 456.2919 - mse: 456.2919 - val_loss: 1795.0337 - val_mse: 1795.0337\n",
      "Epoch 26/50\n",
      "129/129 [==============================] - 18s 141ms/step - loss: 625.6820 - mse: 625.6820 - val_loss: 2134.2947 - val_mse: 2134.2947\n",
      "Epoch 27/50\n",
      "129/129 [==============================] - 18s 140ms/step - loss: 470.8811 - mse: 470.8811 - val_loss: 1673.2455 - val_mse: 1673.2455\n",
      "Epoch 28/50\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 452.4148 - mse: 452.4148 - val_loss: 2238.6765 - val_mse: 2238.6765\n",
      "Epoch 29/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 401.0170 - mse: 401.0170 - val_loss: 2406.0481 - val_mse: 2406.0481\n",
      "Epoch 30/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 405.9096 - mse: 405.9096 - val_loss: 2173.6709 - val_mse: 2173.6709\n",
      "Epoch 31/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 431.3080 - mse: 431.3080 - val_loss: 1619.3306 - val_mse: 1619.3306\n",
      "Epoch 32/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 393.1986 - mse: 393.1986 - val_loss: 2114.6794 - val_mse: 2114.6794\n",
      "Epoch 33/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 412.0683 - mse: 412.0683 - val_loss: 2065.8235 - val_mse: 2065.8235\n",
      "Epoch 34/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 494.7396 - mse: 494.7396 - val_loss: 2100.3406 - val_mse: 2100.3406\n",
      "Epoch 35/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 481.4631 - mse: 481.4631 - val_loss: 2353.0229 - val_mse: 2353.0229\n",
      "Epoch 36/50\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 482.3886 - mse: 482.3886 - val_loss: 2454.8308 - val_mse: 2454.8308\n",
      "Epoch 37/50\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 537.7689 - mse: 537.7689 - val_loss: 1986.1071 - val_mse: 1986.1071\n",
      "Epoch 38/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 480.5613 - mse: 480.5613 - val_loss: 1841.4617 - val_mse: 1841.4617\n",
      "Epoch 39/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 422.3193 - mse: 422.3193 - val_loss: 2403.1836 - val_mse: 2403.1836\n",
      "Epoch 40/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 411.1871 - mse: 411.1871 - val_loss: 1688.5093 - val_mse: 1688.5093\n",
      "Epoch 41/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 386.7851 - mse: 386.7851 - val_loss: 2327.6858 - val_mse: 2327.6858\n",
      "Epoch 42/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 539.3641 - mse: 539.3641 - val_loss: 2354.4890 - val_mse: 2354.4890\n",
      "Epoch 43/50\n",
      "129/129 [==============================] - 18s 139ms/step - loss: 460.6711 - mse: 460.6711 - val_loss: 2080.7664 - val_mse: 2080.7664\n",
      "Epoch 44/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 420.7363 - mse: 420.7363 - val_loss: 1882.7294 - val_mse: 1882.7294\n",
      "Epoch 45/50\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 368.4271 - mse: 368.4271 - val_loss: 1972.3926 - val_mse: 1972.3926\n",
      "Epoch 46/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 440.7588 - mse: 440.7588 - val_loss: 1898.5284 - val_mse: 1898.5284\n",
      "Epoch 47/50\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 444.4809 - mse: 444.4809 - val_loss: 2091.0310 - val_mse: 2091.0310\n",
      "Epoch 48/50\n",
      "129/129 [==============================] - 18s 138ms/step - loss: 429.4972 - mse: 429.4972 - val_loss: 2371.1135 - val_mse: 2371.1135\n",
      "Epoch 49/50\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 396.7541 - mse: 396.7541 - val_loss: 2193.8857 - val_mse: 2193.8857\n",
      "Epoch 50/50\n",
      "129/129 [==============================] - 18s 137ms/step - loss: 413.7266 - mse: 413.7266 - val_loss: 2965.9253 - val_mse: 2965.9253\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data, train_labels, epochs = 50, batch_size = batch_size, validation_data = (val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24c41832",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('metrics_.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02750a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfod",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
